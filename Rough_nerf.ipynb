{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "\n",
    "class NerfModels(nn.Module):\n",
    "    def __init__(self, numLayers, xyzDims, dirDims, batchSize, skipLayer, linearUnits):\n",
    "        super(NerfModels, self).__init__()\n",
    "        \n",
    "        self.xyzDims = xyzDims\n",
    "        self.dirDims = dirDims\n",
    "        self.batchSize = batchSize\n",
    "        self.skipLayer = skipLayer\n",
    "        self.linearUnits = linearUnits\n",
    "        \n",
    "        \n",
    "        self.linearLayers = nn.ModuleList(\n",
    "            [nn.Linear(3,self.linearUnits)] + \n",
    "            [nn.Linear(self.linearUnits, self.linearUnits) if (i % self.skipLayer == 0 and i > 0) else nn.Linear(self.linearUnits + 3, self.linearUnits) \n",
    "                                          for i in range(numLayers-1)]\n",
    "        )\n",
    "        \n",
    "        self.sigmaLayer = nn.Linear(self.linearUnits, 1)\n",
    "        \n",
    "        self.featureLayer = nn.Linear(self.linearUnits, self.linearUnits)\n",
    "        self.lastLinearLayer = nn.Linear(self.linearUnits, self.linearUnits)\n",
    "        self.rgbLayer = nn.Linear(self.linearUnits, 3)\n",
    "    \n",
    "    def forward(self, input_ray, input_dir ):\n",
    "        \n",
    "        x = input_ray\n",
    "        for i, _ in enumerate(self.linearLayers):\n",
    "            x = self.linearLayers[i](x)\n",
    "            x = F.relu(x)\n",
    "            if (i % self.skipLayer == 0) and (i > 0):\n",
    "                x = torch.cat([input_ray, x], -1)\n",
    "                \n",
    "        sigma = self.sigmaLayer(x)\n",
    "        \n",
    "        feature = self.featureLayer(x)\n",
    "        feature = torch.cat([feature, input_dir], -1)\n",
    "        \n",
    "        x = self.lastLinearLayer(x)\n",
    "        \n",
    "        rgb = self.rgbLayer(x)\n",
    "        \n",
    "        return (rgb, sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def render_image_depth(rgb, sigma, tVals):\n",
    "    \n",
    "    sigma = torch.squeeze(sigma)\n",
    "    \n",
    "    diff = tVals[..., 1:] - tVals[..., :-1]\n",
    "    diff = torch.cat([diff, torch.Tensor([1e10]).expand(diff[...,:1].shape)], -1)\n",
    "    \n",
    "    alpha = 1.0 - torch.exp( - sigma * diff)\n",
    "    \n",
    "    transmittance  = torch.cumprod(\n",
    "                torch.cat([torch.ones((alpha.shape[0], 1)), 1.-alpha + 1e-10], -1), -1)[:, :-1]\n",
    "    weights = alpha * transmittance\n",
    "    \n",
    "    image = torch.sum(weights[...,None] * rgb, -2)\n",
    "    depth = torch.sum(weights * tVals, -1)\n",
    "    \n",
    "    # return rgb, depth map and weights\n",
    "    return (image, depth, weights)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_position(x, dims):\n",
    "    \n",
    "    positions = [x]\n",
    "    for i in range(dims):\n",
    "        for fn in [torch.sin , torch.cos]:\n",
    "            positions.append(fn(2.0 ** i * x))\n",
    "    \n",
    "    return torch.concat(positions, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_pdf(tValsMid, weights, nF, batchSize, imageHeight, imageWidth):\n",
    "\t# add a small value to the weights to prevent it from nan\n",
    "\tweights += 1e-5\n",
    "\t# normalize the weights to get the pdf\n",
    "\tpdf = weights / torch.sum(weights, dim=-1, keepdims=True)\n",
    "\t# from pdf to cdf transformation\n",
    "\tcdf = torch.cumsum(pdf, axis=-1)\n",
    "\t# start the cdf with 0s\n",
    "\tcdf = torch.concat([torch.zeros_like(cdf[..., :1]), cdf], -1)\n",
    "\t# get the sample points\n",
    "\tu = torch.rand(shape=[batchSize, imageHeight, imageWidth, nF])\n",
    "\t# get the indices of the points of u when u is inserted into cdf in a\n",
    "\t# sorted manner\n",
    "\tindices = torch.searchsorted(cdf, u, side=\"right\")\n",
    "\t# define the boundaries\n",
    "\tbelow = torch.maximum(0, indices-1)\n",
    "\tabove = torch.minimum(cdf.shape[-1]-1, indices)\n",
    "\tindicesG = torch.stack([below, above], dim=-1)\n",
    "\t\n",
    "\t# gather the cdf according to the indices\n",
    "\tcdfG = torch.gather(cdf, indicesG, axis=-1,\n",
    "\t\tbatch_dims=len(indicesG.shape)-2)\n",
    "\t\n",
    "\t# gather the tVals according to the indices\n",
    "\ttValsMidG = torch.gather(tValsMid, indicesG, axis=-1,\n",
    "\t\tbatch_dims=len(indicesG.shape)-2)\n",
    "\t# create the samples by inverting the cdf\n",
    "\tdenom = cdfG[..., 1] - cdfG[..., 0]\n",
    "\tdenom = torch.where(denom < 1e-5, torch.ones_like(denom), denom)\n",
    "\tt = (u - cdfG[..., 0]) / denom\n",
    "\tsamples = (tValsMidG[..., 0] + t * \n",
    "\t\t(tValsMidG[..., 1] - tValsMidG[..., 0]))\n",
    "\t\n",
    "\t# return the samples\n",
    "\treturn samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
